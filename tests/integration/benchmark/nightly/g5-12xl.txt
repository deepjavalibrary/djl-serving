[test_name]
llama2
[vars]
ENGINE={vllm,lmi-dist}
[container]
deepjavalibrary/djl-serving:lmi-nightly
[serving_properties]
option.rolling_batch=$ENGINE
option.model_id=s3://djl-llm/llama-2-7b-hf/
option.tensor_parallel_degree=max
[aws_curl]
TOKENIZER=TheBloke/Llama-2-7B-fp16 ./awscurl -c 32 -N 10 \
-X POST http://127.0.0.1:8080/invocations   \
--connect-timeout 60   -H "Content-type: application/json"   \
-d '{"inputs":"The new movie that got Oscar this year","parameters":{"max_new_tokens":256, "do_sample":true}}'   \
-t -o /tmp/output.txt
[test_name]
llama3
[vars]
ENGINE={vllm,lmi-dist}
[container]
deepjavalibrary/djl-serving:lmi-nightly
[serving_properties]
engine=Python
option.rolling_batch=$ENGINE
option.model_id=s3://djl-llm/llama-3-8b-hf/
option.tensor_parallel_degree=max
[aws_curl]
TOKENIZER=TheBloke/Llama-2-13B-fp16 ./awscurl -c 32 -N 10 \
-X POST http://127.0.0.1:8080/invocations   \
--connect-timeout 60   -H "Content-type: application/json"   \
-d '{"inputs":"The new movie that got Oscar this year","parameters":{"max_new_tokens":256, "do_sample":true}}'   \
-t -o /tmp/output.txt
