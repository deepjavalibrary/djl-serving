name: LMI-Dist dependency build

on:
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  create-runners-p4d:
    runs-on: [ self-hosted, scheduler ]
    steps:
      - name: Create new P4d.24xl instance
        id: create_gpu_p4d
        run: |
          cd /home/ubuntu/djl_benchmark_script/scripts
          token=$( curl -X POST -H "Authorization: token ${{ secrets.ACTION_RUNNER_PERSONAL_TOKEN }}" \
          https://api.github.com/repos/deepjavalibrary/djl-serving/actions/runners/registration-token \
          --fail \
          | jq '.token' | tr -d '"' )
          ./start_instance.sh action_lmic_p4d $token djl-serving
    outputs:
      p4d_instance_id: ${{ steps.create_gpu_p4d.outputs.action_lmic_p4d_instance_id }}

  lmi-deps-build:
    runs-on: [ self-hosted, p4d ]
    container:
      image: nvidia/cuda:12.4.1-devel-ubuntu22.04
      options: --gpus all --runtime=nvidia --shm-size 20g
    timeout-minutes: 90
    needs: create-runners-p4d
    steps:
      - uses: actions/checkout@v4
      - name: Setup Environment
        run: |
          apt-get update
          apt-get install -y software-properties-common wget libaio-dev g++ git gcc
          mkdir build_artifacts
      - name: Set up Python3
        run: |
          ./serving/docker/scripts/install_python.sh 3.10
      - name: Install torch dependencies
        run: |
          python -m venv venv
          . ./venv/bin/activate
          python -m pip install --upgrade pip
          python -m pip install "numpy<2" cmake awscli packaging wheel setuptools ninja git-remote-codecommit \
                                torch==2.3.0 --extra-index-url https://download.pytorch.org/whl/cu121
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::185921645874:role/github-actions-djl-serving
          aws-region: us-east-1
      - name: Build FlashAttn V2
        run: |
          . ./venv/bin/activate
          export FLASH_ATTENTION_FORCE_BUILD=TRUE
          git clone https://github.com/ymwangg/flash-attention flash-attention-v2 -b specdec_v0.4.2
          cd flash-attention-v2
          pip wheel . --no-deps
          cp flash_attn-*.whl ../build_artifacts
      - name: Build vllm 0.4.2 LoRA TP fix
        run: |
          . ./venv/bin/activate
          git clone https://github.com/rohithkrn/vllm -b 0.4.2-lora-tp-fix
          cd vllm
          export TORCH_CUDA_ARCH_LIST="7.5 8.0 8.6 8.9 9.0+PTX"
          export VLLM_INSTALL_PUNICA_KERNELS=1
          pip wheel . --no-deps
          cp vllm-*.whl ../build_artifacts
      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: build_artifacts/

  lmi-deps-upload:
    runs-on: [ self-hosted, p4d ]
    needs: lmi-deps-build
    steps:
      - name: Set up Python3
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: pip install awscli
      - name: Download built-artifacts
        uses: actions/download-artifact@v3
        with:
            name: build-artifacts
      - name: upload to S3
        run: |
          aws s3 cp flash_attn-2*.whl s3://djl-ai-staging/publish/flash_attn/cu124-pt230/
          aws s3 cp vllm*.whl s3://djl-ai-staging/publish/vllm/cu124-pt230/

  stop-runners-p4d:
    if: always()
    runs-on: [ self-hosted, scheduler ]
    needs: [ create-runners-p4d, lmi-deps-build, lmi-deps-upload ]
    steps:
      - name: Stop all instances
        run: |
          cd /home/ubuntu/djl_benchmark_script/scripts
          instance_id=${{ needs.create-runners-p4d.outputs.p4d_instance_id }}
          ./stop_instance.sh $instance_id
