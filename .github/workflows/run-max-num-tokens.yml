# Placeholder file - work-in-progress
name: Max-Num-Tokens Running

on:
  workflow_dispatch:
    inputs:
      running_template:
        description: 'A json file that contains model and tp pairs (see default for example):'
        default: 'https://gist.githubusercontent.com/ydm-amazon/0d264b365ba4fb3082ec58151c9b25c2/raw/e3ecd13b8141db5da2748046745f5fc0502fa0e0/gistfile1.txt'
        required: true
      instance:
        description: 'Instance for max-num-tokens calculation:'
        required: true
        default: 'g5.12xlarge'
        type: choice
        options:
          - g5.2xlarge
          - g5.12xlarge
          - g5.48xlarge
          - p4d.24xlarge

permissions:
  id-token: write
  contents: read

jobs:
  create-runners:
    runs-on: [self-hosted, scheduler]
    steps:
      - name: Create new instance
        id: create_instance
        run: |
          cd /home/ubuntu/djl_benchmark_script/scripts
          token=$( curl -X POST -H "Authorization: token ${{ secrets.ACTION_RUNNER_PERSONAL_TOKEN }}" \
          https://api.github.com/repos/deepjavalibrary/djl-serving/actions/runners/registration-token \
          --fail \
          | jq '.token' | tr -d '"' )
          # borrow IB logic of creating instances
          ./start_instance.sh action_ib_${{ inputs.instance }} $token djl-serving
    outputs:
      gpu_instance_id: ${{ steps.create_instance.outputs.action_ib_instance_id }}

  run-max-num-tokens:
    runs-on: [ self-hosted, "${{ inputs.instance }}" ]
    container:
      image: deepjavalibrary/djl-serving:tensorrt-llm-nightly
      options: --gpus all --runtime=nvidia --shm-size 12g
    timeout-minutes: 90
    needs: create-runners
    steps:
      - uses: actions/checkout@v4
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::185921645874:role/github-actions-djl-serving
          aws-region: us-east-1
      - name: Run Max-Num-Tokens script
        working-directory: tests/integration
        run: |
          python3 llm/run_max_num_tokens.py "${{ inputs.running_template }}"
      - name: Upload test logs
        uses: actions/upload-artifact@v3
        with:
          path: tests/integration/max_num_token_results/

  stop-runners:
    if: always()
    runs-on: [ self-hosted, scheduler ]
    needs: [ create-runners, run-max-num-tokens ]
    steps:
      - name: Stop all instances
        run: |
          cd /home/ubuntu/djl_benchmark_script/scripts
          instance_id=${{ needs.create-runners.outputs.gpu_instance_id }}
          ./stop_instance.sh $instance_id
